{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "549cf197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f3484329",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "481a5ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9ae04961",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0].ndim\n",
    "# train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5777e79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0f654dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1ElEQVR4nGNgGArA+YU6AwMDAwMTAwMDg10gqqTpGQaEpEMQihyTohwjgndnMYqk9L9FSDqZUE2dw3AbIaknjirJz7AbIenFiSInrsjwFCGpznAVWbJH/NZnCIuFgYGBgeE0XIbPI8aNofkDsqQQAwODPpOzDFs00/eTP1nOQlUyMjAwTEv/8IiBQY/xz7drJ88cfPlEkI0BoTProRUDA8OjjddOMDAwMKSJ3mPACVb+64QxmbBIb8AnyYBHklEVj+R/JjySDJb4jMVj5/b/OB1IJQAAg3ksR3QPgSAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im = Image.fromarray(train_images[2])\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b066e05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow import keras\n",
    "# from tensorflow.keras import layers\n",
    "# model = keras.Sequential([\n",
    "#                             layers.Dense(512, activation=\"relu\"),\n",
    "#                             layers.Dense(10, activation=\"softmax\")\n",
    "#                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0e17165c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array([1,2,4]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be27dac2",
   "metadata": {},
   "source": [
    "# Another way to create a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2c7210c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models,layers\n",
    "\n",
    "model = models.Sequential()   \n",
    "\n",
    "model.add(layers.Dense(512, activation='relu', input_shape=(28*28,)))\n",
    "\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadfbd2f",
   "metadata": {},
   "source": [
    "# Before fitting model must be compiled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2395200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"rmsprop\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f41f18e",
   "metadata": {},
   "source": [
    "# Data must be in ths shape as the the model required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3ae5a53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images= train_images.reshape((60000, 784))\n",
    "                                    \n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "\n",
    "\n",
    "test_images = test_images.reshape((10000, 784))\n",
    "test_images = test_images.astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f188a92d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d100d74",
   "metadata": {},
   "source": [
    "# Fitting / Trainnig the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dd12ee5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.3232 - accuracy: 0.9094\n",
      "Epoch 2/5\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.1387 - accuracy: 0.9592\n",
      "Epoch 3/5\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0935 - accuracy: 0.9724\n",
      "Epoch 4/5\n",
      "235/235 [==============================] - 5s 20ms/step - loss: 0.0688 - accuracy: 0.9800\n",
      "Epoch 5/5\n",
      "235/235 [==============================] - 5s 21ms/step - loss: 0.0532 - accuracy: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x213f11f8890>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs=5, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b05926",
   "metadata": {},
   "source": [
    "# Model Layers Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e0f43da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               401920    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 407050 (1.55 MB)\n",
      "Trainable params: 407050 (1.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19d54bc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(test_images[[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "adfc1138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39774dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0719 - accuracy: 0.9784\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a7e9459a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'eight.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m eight \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meight.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3224\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[0;32m   3226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[1;32m-> 3227\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   3228\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   3230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'eight.png'"
     ]
    }
   ],
   "source": [
    "eight = Image.open('eight.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16a9dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = eight.convert(\"L\")\n",
    "\n",
    "# Save the grayscale image\n",
    "image.save(\"grayscale_eight.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b564d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eight_grey = Image.open('grayscale_eight.jpg')\n",
    "arr = np.asarray(eight_grey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951bccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr784 = arr.reshape(1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443982aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(model.predict(arr784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a37502fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "four = Image.open('four.jpg')\n",
    "four = four.convert(\"L\")\n",
    "four = four.save('gfour.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ff2df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "four = Image.open('gfour.jpg')\n",
    "four = np.asarray(four).reshape(1,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dbf177e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(four))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a663fab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7f552a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
